# -*- coding: utf-8 -*-
"""TitanicKaggle_EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zyW4_gPKgTevHwvRQo3UJuBq7NwEo1HM
"""

import pandas as pd 
import matplotlib.pyplot as plt 
import seaborn as sns 
import numpy as np

"""#Loading the data"""

train=pd.read_csv('/content/drive/My Drive/Colab Notebooks/Competitions/Titanic Kaggle/train.csv')
test=pd.read_csv('/content/drive/My Drive/Colab Notebooks/Competitions/Titanic Kaggle/test.csv')

"""# Null values"""

train.head()

"""### We will drop id column as it is completly irrelevat here
### however if we were provided with some celebrities names or cast of people we could have feature engg to create a new column called "imp persons". We can still feature engg name column by extracting title from names like Mr,Miss ..etc

### Ticket column can be handled in various ways by feature engg it with other column like cabin , but we will focus on data analysis first
"""

train.isnull().sum()

#Visualizating the null values
plt.figure(figsize=(10,5))
sns.heatmap(train.isnull(),yticklabels=False,xticklabels=True,cbar=False,cmap='Blues')

print("% of data null for cabin column:",sum(train.isnull()['Cabin'])/len(train)*100)
print("% of data null for age column:",sum(train.isnull()['Age'])/len(train)*100)

"""## Before going on to fill null values lets visualize the data first

# Visualzing data per column
"""

train.columns

"""## Pclass

### Categorical feature 

*   1 - Rich class
*   2 - Middle class
*   3 - Poor class
"""

plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
sns.countplot(x='Pclass',data=train)

plt.subplot(1,2,2)
sns.set_style('whitegrid')
sns.countplot(x='Survived',hue='Pclass',data=train)

"""### We can see a lot of poor people(Pclass=3) died in titanic accident
### This feature is important factor for our model

## Gender
"""

plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
sns.countplot(x='Sex',data=train)

plt.subplot(1,2,2)
sns.set_style('whitegrid')
sns.countplot(x='Survived',hue='Sex',data=train)

"""### Majority of male did not survived in accident , the female and children were given priority

## Age
"""

sns.distplot(train['Age'],kde=False,bins=40)

"""### Not a clean column , have many outliers

## Sibsb

### Column tells no.of siblings or relatives.. person was travelling with
"""

plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
sns.countplot(x='SibSp',data=train)

plt.subplot(1,2,2)
sns.set_style('whitegrid')
sns.countplot(x='Survived',hue='SibSp',data=train)

"""### There is no trend as such in this column ...

## Parch

### This column represents no.of parents/children
"""

sns.countplot(x='Survived',hue='Parch',data=train)

"""### This column again represents same details  but it does not have any general trend with respect to survival

## Fare
"""

plt.figure(figsize=(10,5))
sns.distplot(train['Fare'],kde=False)

"""### There are some outliers clearly visible in fare column
### These need to handled if we decide to use models like logistic regression otherwise can be ignored in case of trees classifiers

## Embarked
"""

plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
sns.countplot(x='Embarked',data=train)

plt.subplot(1,2,2)
sns.set_style('whitegrid')
sns.countplot(x='Survived',hue='Embarked',data=train)

"""Not a great factor for model as of now , no such trend 
Gives us a information though ..lot of people boarded ship from port S , makes sense since S(Southampton) was the place were titanic started

# Feature relation
"""

plt.figure(figsize=(10,5))
corr=train.corr()
sns.heatmap(corr[((corr >= 0.3) | (corr <= -0.3)) & (corr != 1)],cmap='Blues',annot=True,fmt='.2f')

"""1.  We can see parch and SibSp seem to co-relate with each other 
2.  Fare vs Pclass
3.  Age vs Pclass
4.  Age vs SibSp
"""

train.columns

"""## Age vs Pclass"""

sns.boxplot(x='Pclass',y='Age',data=train)
# Lot of younger people are from class3 and old people belong to class1 , linear relation between Pclass and age

"""## Fare vs Pclass"""

sns.catplot(x="Pclass", y="Fare", kind="swarm", data=train, height = 6)
# Rich Pclass people have bought higher priced ticket and class 2 & 3 have bought similar rate tickets

"""## Age vs SibSp"""

sns.catplot(x="SibSp", y="Age", kind="swarm", data=train, height = 6)

"""Passanger with SibSp of 4-5 are kids of age below 20. 
Lot of older people that are travelling alone or with a spouse

# Fill Null Values
"""

train.groupby('Pclass')['Age'].mean()

sns.boxplot(x='Sex',y='Age',data=train)

train.groupby('Sex')['Age'].mean()

train.groupby(['Pclass','Sex'])['Age'].mean()

"""We have used Pclass , Sex as other factors to fill null values in Age"""

def fill_age(cols):
  age=cols[0]
  pclass=cols[1]
  gender=cols[2]
  if pd.isnull(age):
    if pclass==1 and gender=='male':
      return 41
    if pclass==1 and gender=='female':
      return 37
    if pclass==2 and gender=='male':
      return 31
    if pclass==2 and gender=='female':
      return 27
    if pclass==3 and gender=='male':
      return 26
    if pclass==3 and gender=='female':
      return 22
  else:
    return age

train['Age']=train[['Age','Pclass','Sex']].apply(fill_age,axis=1)
test['Age']=test[['Age','Pclass','Sex']].apply(fill_age,axis=1)

"""Filling embarked missing values with mode"""

train['Embarked']=train['Embarked'].fillna(train['Embarked'].value_counts().index[0])
test['Embarked']=test['Embarked'].fillna(test['Embarked'].value_counts().index[0])

"""Filling the fare null values in test data by its mean , we can also use Pclass factor to fill null values of fare as we did it in age columns. But for now we will fill it by mean value becuase only 1 value of fare is null"""

test['Fare']=test['Fare'].fillna(np.mean(test['Fare']))

"""We will fill null values of cabin by U meaning unknown rather than dropping it because it may be helpful in feature engg ahead"""

train['Cabin']=train['Cabin'].fillna(value='U')
test['Cabin']=test['Cabin'].fillna(value='U')

train.isnull().sum()

test.isnull().sum()

"""# Feature Engg"""

# Lets extract some more relevant features from given data

"""### Name"""

#let's extract Titles of Passengers
train['Title']=train['Name'].str.extract('([A-Za-z]+)\.',)
test['Title']=test['Name'].str.extract('([A-Za-z]+)\.',)

plt.figure(figsize=(8,8))
sns.countplot(train['Title'])

# There are lot of titles but only 4 are frequently occuring 
train['Title'] = train['Title'].replace(['Rev', 'Dr', 'Col', 'Ms', 'Mlle', 'Major', 'Countess', 
                                       'Capt', 'Dona', 'Jonkheer', 'Lady', 'Sir', 'Mme', 'Don'], 'Other')
test['Title'] = test['Title'].replace(['Rev', 'Dr', 'Col', 'Ms', 'Mlle', 'Major', 'Countess', 
                                       'Capt', 'Dona', 'Jonkheer', 'Lady', 'Sir', 'Mme', 'Don'], 'Other')

sns.catplot(y='Title',x='Survived',data=train,kind='bar')

"""### Sibsp + Parch"""

#sibsp - Number of Siblings/Spouses Aboard. parch - Number of Parents/Children --> We need to feature engg these column as parch and sibsb are highly correlated   
train['Family_Size']=train['Parch']+train['SibSp']+1
test['Family_Size']=test['Parch']+test['SibSp']+1

"""### Cabin"""

import re

train['Cabin'] = train['Cabin'].map(lambda x:re.compile("([a-zA-Z])").search(x).group())
test['Cabin'] = test['Cabin'].map(lambda x:re.compile("([a-zA-Z])").search(x).group())

train['Cabin'].unique()

plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
sns.countplot(x='Cabin',data=train)

plt.subplot(1,2,2)
sns.set_style('whitegrid')
sns.countplot(x='Survived',hue='Cabin',data=train)

"""Lot of people did not survive who had no cabin alloted. May be they belonged to Pclass 3 and paid less fare. Lets check."""

unknown_cabin=train[train['Cabin']=='U']

unknown_cabin['Pclass'].value_counts()

unknown_cabin.groupby('Pclass')['Fare'].mean()

"""## Tickets"""

ticket_fare_cabin=pd.DataFrame(train.groupby(['Cabin','Pclass'])['Ticket'].unique())

ticket_fare_cabin.to_dict()

"""Lets Observe some points in ticket column:-


*   T Cabin was alloted only to one person of Pclass 1 with ticket no:-113784
*   Cabin A,B,C,D was never alloted to person of Pclass 3, infact Cabin A,B,C were only given to Pclass 1
*   Cabin E,F,G were given to Pclass 2 and 3
*   Majority of Pclass 3 were given unkown cabins
"""

#We can make new columns from cabin+pclass as Superior_Cabins and Non-Superior_Cabins
def superior_cabins(df):
  if df['Cabin']=='A' or df['Cabin']=='B' or df['Cabin']=='C' or df['Cabin']=='D' or df['Cabin']=='T':
    return 1
  if df['Cabin']=='E' or df['Cabin']=='F' or df['Cabin']=='G':
    return 0
  if df['Cabin']=='U' and df['Pclass']==1:
    return 1
  if df['Cabin']=='U' and df['Pclass']==2:
    return 0
  if df['Cabin']=='U' and df['Pclass']==3:
    return 0

train['Superior_Cabins']=train.apply(lambda x:superior_cabins(x),axis=1)

test['Superior_Cabins']=test.apply(lambda x:superior_cabins(x),axis=1)

train.groupby(['Cabin','Embarked'])['Ticket'].unique().to_dict()

"""Titanic journey started from Southampton(S) to Cherbourg(C) and then Queenstown(Q)
1. C represented in tickets may represent that journey started from Cherbourg
2. Less tickets sold of Queenstown ( we can also see fare comparison of tickets as per embarked,we will explore this next)
3. We can probably map the entire tickets with design of ship using cabin and embarked columns but that will require a lot of knwoledge about titanic ship

## Fare
"""

train[train['Fare']==0]['Survived'].value_counts()
# Some people got tickets for free...wohooo! But majority of them could not survive

sns.catplot(x='Embarked',y='Fare',data=train)

"""Fairly similar prices of tickets of S and C and very less fare from Q(last stop of ship). Cherbourg(Paris) seems to be the place where rich people boarded the ship!"""

train.head()

"""# Handling categorical features

1.   Pclass
2.   Sex
3.   Embarked
4.   Title 
5.   Cabin
"""

def convert_categorical(data,cols): # cols=['Sex','Pclass','Embarked','Title','Cabin']
  cat1=pd.get_dummies(data[cols[0]],drop_first=True)
  cat2=pd.get_dummies(data[cols[1]],drop_first=True)
  cat3=pd.get_dummies(data[cols[2]],drop_first=True)
  cat4=pd.get_dummies(data[cols[3]],drop_first=True)
  cat5=pd.get_dummies(data[cols[4]],drop_first=True)
  data=pd.concat([data,cat1,cat2,cat3,cat4,cat5],axis=1)
  data.drop(cols,axis=1,inplace=True)

  return data

train=convert_categorical(cols=['Sex','Pclass','Embarked','Title','Cabin'],data=train)

train.head()

test=convert_categorical(cols=['Sex','Pclass','Embarked','Title','Cabin'],data=test)

train.columns

test.columns

# Lets add t binary columns missing in test dataset
test['t']=0

"""# Feature selection"""

X = train.drop(['Name','Ticket','Survived','PassengerId'],axis=1)
y = train['Survived']

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
X=scaler.fit_transform(X)

"""## Univariate Selection"""

from sklearn.feature_selection import SelectKBest,chi2
feature_imp=SelectKBest(score_func=chi2, k=10)

imp=feature_imp.fit(X,train['Survived'])

f_imp=pd.DataFrame(imp.scores_,columns=['Score'])
f_imp['Columns']=train.drop(['Name','Ticket','Survived','PassengerId'],axis=1).columns

f_imp.sort_values('Score',ascending=False)

"""## Extra-Tress Classifier Selection"""

from sklearn.ensemble import ExtraTreesClassifier
import matplotlib.pyplot as plt
model = ExtraTreesClassifier()
model.fit(X,y)
print(model.feature_importances_) 

feat_importances = pd.Series(model.feature_importances_, index=train.drop(['Name','Ticket','Survived','PassengerId'],axis=1).columns)
feat_importances.nlargest(21).plot(kind='barh')
plt.show()

"""## Correlation Matrix Method"""

pd.DataFrame(train.corr()['Survived']).sort_values('Survived',ascending=False)

"""Best Columns:-
1. Fare
2. Age 
3. Mr,Miss,Mrs
4. Age 
5. Pclass
6. Superior Cabins
"""

train.to_csv('train_clean.csv',index=False)
test.to_csv('test_clean.csv',index=False)

